\section{Normalisation of STLC}

%%
%%  Introduction
%%

\subsection{Introduction}
We now wish to analyse the computational power of our type theory.
When designing the type checking algorithm we made a point not to invoke any computational rules, since we want to be able to spot a correct program without running it. This is an issue later on where we see \emph{untyped} terms may not \emph{normalise}.

Computational rules, are our basic steps of computation. In the late 1930s, Alan Turing had a model of what it meant to be \emph{effectively calculable}, now known as a Turing Machine \cite{turing1936a}. Critically he included an appendix which outlined how Church's untyped lambda calculus was equivalent to his notion of effective calculability. We will discuss the historical nature of this further in chapter \ref{logic_chapter}.

One important question in computer science is knowing whether or not a computation will halt, known as the \emph{Halting problem}. It can in fact be shown that Turing machines, and by extension untyped lambda calculus, cannot decide their own halting problem. This stems from the fact that these gadgets are ``\emph{too good}'' at computation. It is closely related to G\"odel's analysis of the power of arithmetic. \cite{}

The main goal of this chapter will be to show that the STLC, defined in the previous chapter, has computations that \emph{always} terminate. This is known as \emph{strong normalisation}. This immediately highlights some of the weaknesses of the STLC, however we will later discuss what is missing and how this can be fixed. The technical term for this is that STLC is \emph{not} Turing-complete. \cite{} We will also see that there are \emph{untyped} lambda terms that cannot be \emph{typed}.

It can be observed that there is not a unique way to compute something, i.e. run the program. What is important is that the result is unique. Such a property is known as the Church-Rosser property. We will show that Church-Rosser property holds for $\beta$-, $\eta$- and $\beta\eta$-reductions. 

Finally we will discuss the issue of canonicity and modifications to the STLC, and what they mean with respect to these computational properties.

Guiding references for this chapter are \cite{Sorensen} and \cite{BarendregtHenk2013Lcwt}.

\subsection{Well-founded relations}

The notion of well-founded induction is a standard theorem of set theory. The classical proof of which usually uses the law of excluded middle \cite[p. 62]{johnstone1987notes}, \cite[Ch. 7]{barwise1982handbook}. It's use in the formal semantics of programming languages is not much different either \cite[Ch. 3]{winskel1993formal}. There are however more constructive notions of well-foundedness \cite[\S 8]{2018arXiv180805204S} with more careful use of excluded middle. We will follow \cite{10.2307/2275781}, as this is the simplest to understand, and we won't be using this material much other than an initial justification for induction in classical mathematics.

\begin{defin}
    Let $X$ be a set and $\prec$ a binary relation on $X$. A subset $Y \subseteq X$ is called \textbf{$\prec$-inductive} if
    $$
        \forall x \in X, \quad (\forall y \prec x,\ y \in Y) \Rightarrow x \in Y.
    $$
\end{defin}

\begin{defin}\label{wf}
    The relation $\prec$ is \textbf{well-founded} if the only $\prec$-inductive subset of $X$ is $X$ itself. A set $X$ equipped with a well-founded relation is called a \textit{well-founded set}.
\end{defin}

\begin{theorem}[Well-founded induction]
    Let $X$ be a well-founded set and $P$ a property of the elements of $X$ (a proposition). Then
    $$
        \forall x \in X, P(x) \quad \iff \quad  \forall x \in X,\ \ (\forall y \prec x, P(y)) \Rightarrow P(x).
    $$
\end{theorem}

\begin{proof}
    The forward direction is clearly true. For the converse, assume $\forall x \in X,((\forall y \prec x, P(y)) \Rightarrow P(x))$. Note that $P(y) \Leftrightarrow x \in Y := \{ x \in X \mid P(x)\} $ which means our assumption is equivalent to $\forall x \in X,\ (\forall y \prec x,\ y \in Y) \Rightarrow x \in Y$ which means $Y$ is $\prec$-inductive by definition. Hence by \ref{wf} $Y=X$ giving us $ \forall x \in X, P(x)$.
\end{proof}

% Compatible relation
First we define what we mean by a binary relation being \emph{compatible} with the syntax of the STLC.
\begin{defin}
    A binary relation $\succ$ on $\mathrm{Term}$ the set of all terms, is said to be \emph{compatible with the syntax of STLC} (or just simply \emph{compatible}) if the following conditions hold:
    \begin{enumerate}
        \item If $M \succ N$ then $\lambda x . M \succ \lambda x . N$.
        \item If $M \succ N$ then $M Z \succ N Z$.
        \item If $M \succ N$ then $Z M \succ Z N$.
        \item If $M \succ N$ then $(Z,M) \succ (Z,N)$.
        \item If $M \succ N$ then $(M, Z) \succ (N, Z)$.
    \end{enumerate}
\end{defin}

\begin{remark}
    The notion of compatibility allows us to make sure a relation also considers sub-terms. This is a tricky thing to get right but due to our focus on the correct structure of syntax we are fine.
\end{remark}

\begin{remark}
[[CLEAN THIS UP]]
    The reader may ask what relations have to do with normalisation, but it is a formalism that we have chosen. This is definitely not the only way to prove properties like Church-Rosser. The main reason we have chosen this method is for its simplicity. In fact earlier we discussed the dynamics of languages, this is exactly that. There are many ways to go about dynamics including transition systems and equational dynamics. Our approach corresponds to the more classical and simple transition systems approach. It can be shown that this is equivalent to equational dynamics in that a reduction step will be justified by application of rules from STLC.
\end{remark}

We will demonstrate our last remark by considering the following relation:

% same type relation
\begin{defin}
    Let $\sim_{\ty}$ denote the relation among terms of \emph{having the same type}. Suppose $\Gamma \vdash s \Leftarrow S$ and $\Gamma \vdash t \Leftarrow T$, then:
    $$
        s \sim_{\ty} t \iff \Gamma \vdash S \equiv T \ \mathsf{type}
    $$
\end{defin}

% having the same type is a compatible relation
\begin{lemma}
    The relation $\sim_{\ty}$ is a compatible relation.
\end{lemma}

\begin{proof}
    Suppose $M \sim_{\ty} N$, then we have $\Gamma \vdash M \Leftarrow S$, $\Gamma \vdash N \Leftarrow T$ and $\Gamma \vdash S \equiv T \ \mathsf{type}$.
    \begin{enumerate}
        \item [[TODO FINISH]]
    \end{enumerate}
\end{proof}

% Transitive and reflexive closure
\begin{defin}
    Given a relation $\succ$ on a set $X$, we denote by $\succ^+$ the \emph{transitive closure} of $\succ$. This is the smallest relation which coincides with $\succ$ and is transitive. We also consider the \emph{reflexive-transitive closure} $\succ^*$ of $\succ$ which is simply the relation $\Delta(X)\cup \succ^+ $ where $\Delta(X)$ is the image of the diagonal function $x \mapsto (x,x)$. (We've simply added that $x \succ^* x$)
\end{defin}

\begin{remark}
    Transitive closures correspond to chains of the relation, and reflexive-transitive closures allow for chains of length $0$. It should also be noted that we took the \emph{union} of a relation. This is a well-defined notion and can easily be seen to be a relation.
\end{remark}

Let $\to$ be a binary relation on a set $A$, $\twoheadrightarrow^+$ be its transitive closure and $\twoheadrightarrow$ be its reflexive-transitive closure.

\subsection{Normalising relations}

Now we define (very generally) what it means for an element of a set to be in \emph{normal form} and \emph{normalising} with respect to some relation.

% normal form with respect to a relation
\begin{defin}
    An element $a \in A$ is said to be of \emph{normal form} if $\forall b \in A$, $a {\not \to} b$.
\end{defin}

% weak normalisation with respect to a relation
\begin{defin}
    An element $a \in A$ is said to be \emph{normalising} (or \emph{weakly normalising}) if there is a reduction sequence $a \to a_1 \to a_2 \to \cdots \to a_n$ where $a_n$ is in normal form, for some $n$. We call $a_n$ a \emph{normal form} or \emph{reduct} of $a$.
\end{defin}

% 
\begin{remark}
    Note that not every reduction sequence is guaranteed to be finite. We also note that if $\to$ a relation is Church-Rosser (to be defined below) then $a_n$ is \emph{the} normal form or reduct.
\end{remark}

We discuss what it means for a relation to be Church-Rosser:

% Church-Rosser
\begin{defin}
    A relation $\to$ has the \emph{Church-Rosser} (CR) property if and only if for all $a,b,c \in A$ such that $a \twoheadrightarrow b$ and $a \twoheadrightarrow c$, there exists $d \in A$ with $b \twoheadrightarrow d$ and $c \twoheadrightarrow d$.
\end{defin}

\begin{remark}
    This says no matter what path we take along a relation, there will always be elements at which the paths cross.
\end{remark}

We will also need a slightly weaker version called weak Church-Rosser, for reasons we will see later:

% weak Church-Rosser
\begin{defin}
    A relation $\to$ has the \emph{weak Church-Rosser} (WCR) property if and only if for all $a, b, c \in A$ such that $a \to b$ and $a \to c$, there exists $d \in A$ with $b \twoheadrightarrow d$ and $c \twoheadrightarrow d$.
\end{defin}

We now state the obvious:

\begin{cor}\label{cr_is_wcr}
    If $\to$ is CR then $\to$ is WCR.
\end{cor}

\begin{proof}
    Observe that WCR is a special case of CR.
\end{proof}

The converse to this is in general \emph{false} but it is true when another condition holds, namely that $\to$ is \emph{strongly normalising}.

\begin{defin}
    A binary relation $\to$ is \emph{strongly normalising} (SN) if and only if there is no infinite sequence $a_0 \to a_1 \to a_2 \to  \cdots$.
\end{defin}

\begin{remark}
    In other words, a relation $\to$ is strongly normalising if and only if \emph{every} sequence $a_0 \to a_1 \to a_2 \to  \cdots$ terminates after a finite number of steps.
\end{remark}

\begin{remark}
    We typically also say an element is strongly normalising if the condition holds for that element. This allows us to state SN in a different (and perhaps more correct) way: A relation $\to$ is strongly normalising if each element is strongly normalising with respect to $\to$. Then we can define an element to be strongly normalising if all of it's reducts are strongly normalising. The nice thing about this definition is that we have seen it before, this is precisely what it means to be a \emph{well-founded relation} from Definition \ref{wf}. So $\to$ is strongly normalising if and only if it is well-founded. This is good because we can induct over it!
\end{remark}

\begin{cor}
    If a relation $\to$ is strongly normalising then every element is normalising.
\end{cor}

\begin{proof}
    By induction on $\to$ we see that either an element is in normal form, or it reduces to normal form. This is precisely what it means to be normalising.
\end{proof}

\subsection{Newman's lemma}

We now state a lemma which will be very useful. It is a sufficient condition for the converse of Corollary \ref{cr_is_wcr} to hold.

\begin{lemma}[Newman's Lemma]\label{newman}
    If $\to$ is strongly normalising and WCR then it is CR.
\end{lemma}

\begin{proof}
    Since $\to$ is strongly normalising, any $a \in A$ has a normal form. Call an element \emph{ambiguous} if $a$ reduces to two distinct normal forms. Clearly $\to$ is CR if there are no ambiguous elements of $A$.
    Assume, for contradiction, that there is an ambiguous $a$. We will show that there is another ambiguous $a'$ where $a \to a'$.
    Suppose we have $a \twoheadrightarrow b_1$ and $a \twoheadrightarrow b_2$ where $b_1$ and $b_2$ are two different normal forms. Both reductions must make at least one step, thus both reductions can be written as $a \to a_1 \twoheadrightarrow b_1$ and $a \to a_2 \twoheadrightarrow b_2$.
    Suppose $a_1 = a_2$ then we can choose $a' = a_1 = a_2$. Now suppose $a_1 \neq a_2$, we know by WCR that $a_1 \twoheadrightarrow b_3$ and $a_2 \twoheadrightarrow b_3$ for some $b_3$. We can assume that $b_3$ is a normal form. Since $b_1$ and $b_2$ are distinct, $b_3$ is different from $b_1$ or $b_2$ so we can choose $a' = a_1$ or $a'=a_2$.
    Since we can always choose an $a'$, we can repeat this process and get an infinite chain of ambiguous elements. It is clear that this contradicts strongly normalising, hence $A$ has no ambiguous elements.
\end{proof}


[[TODO add note about the knowledge of Newman's lemma, should be footnote in Sorensen]]


%%
%%  Beta reduction
%%

\subsection{ \texorpdfstring{$\beta$}{}-reduction}

Now we define what we mean by $\beta$-reduction and $\beta$-normal form.

% Define beta-reduction
\begin{defin}\label{beta_reduction}
    We define \emph{$\beta$-reduction} to be the least compatible relation $\to_{\beta}$ on $\mathrm{Term}$ satisfying the following conditions:
    \begin{enumerate}
        \item $(\lambda x . y)t \to_{\beta} y [t / x]$
        \item $\fst(x,y) \to_{\beta} x$
        \item $\snd(x,y) \to_{\beta} y$
    \end{enumerate}
    A term on the left hand side of any of the above is called a \emph{$\beta$-redex} (reducible expression) and the right hand sides are said to \emph{arise by contracting the redex}.
\end{defin}

\begin{remark}
    Observe that these are very similar to our $\beta$ rules, in fact they are exactly those. So the question may arise: why haven't we defined $\beta$-reduction using the rules that we already have? The answer is that we could but we would have a much harder time, the rules also take into account typing information but we are explicitly not worried about that since we will show later $\beta$-reduction doesn't change a typed terms type. It is somewhat simpler and clearer to focus purely on terms. We will later justify calling this $\beta$-reduction.
    Such dynamics falls under what is known as \emph{equational dynamics}. This would require us to have a suitable way of dealing with judgemental equality, which we feel would obstruct the inner workings of the result.[[DROP REFERENCE TO EARLIER SECTION]]
\end{remark}

% Define beta normal form
\begin{defin}
    A term $M$ is said to be in \emph{$\beta$-normal form} if it is in normal form with respect to $\to_\beta$.
\end{defin}

\begin{remark}
    That is to say a term is in $\beta$-normal form if there is no $\beta$-reduction to any other term. Or better yet, $M$ does not contain a $\beta$-redex.
\end{remark}

% Define multi-step beta reductions
\begin{defin}
    Let $\twoheadrightarrow_{\beta}$ be the transitive, reflexive closure of $\to_{\beta}$ called a \emph{multi-step $\beta$-reduction}.
\end{defin}

% Non normalising terms
\begin{remark}\label{beta_non_normalising_remark}
    Not every term is normalising. Take for example the term $\Omega=(\lambda x . x x)(\lambda x . x x)$ which cannot be typed as we will see later. There is an infinite reduction sequence:
    $$
        \Omega \to_{\beta} \Omega \to_{\beta} \Omega \to_{\beta} \Omega \to_{\beta} \cdots
    $$
    Since $\Omega$ cannot be given a type, it is deemed \emph{ill-typed}.
\end{remark}

This means we have to be careful which terms we are talking about. When talking about terms of the STLC we should add that we expect them to be well-typed (derivable). We will see later there are many syntactically valid terms that are ill-typed.

We want to now prove that every derivable term is $\beta$-normalising. In order to do this we need to keep track of available redexes and bound them. We will then show there is a reduction strategy that decreases this bound yielding our result.

This proof is usually attributed to an unpublished note of Turing but it has been rediscovered by various authors. We will follow the proof in Girard's book \cite{Girard1989}.

% Degree of a type
\begin{defin}
    The \emph{degree $\partial(T)$ of a type $T$} is defined by:
    \begin{itemize}
        \item $\partial(T) := 1$ if $T$ is atomic.
        \item $\partial(U \times V), \partial(U \to V) := \max(\partial(U), \partial(V))+1$.
    \end{itemize}
\end{defin}

% Degree of a redex
\begin{defin}
    The \emph{($\beta$-)degree $\partial_{\beta}(t)$ of a redex} is defined by:
    \begin{itemize}
        \item $\partial_{\beta}(\fst(u,v)), \partial_{\beta}(\snd(u,v)) := \partial(U\times V)$ where $\Gamma \vdash (u, v) \Leftarrow U \times V$.
        \item $\partial_{\beta}((\lambda x . v) u) := \partial(U \to V)$ where $\Gamma \vdash \lambda x . v \Leftarrow U \to V$.
    \end{itemize}
\end{defin}

% Degree of a term
\begin{defin}
    The \emph{($\beta$-)degree $d_{\beta}(t)$ of a term} is the maximum of the degrees of its redexes:
    $$
        d_{\beta}(t) := \max \{\partial_{\beta} (s) \mid s \text{ is a redex in } t\}
    $$
\end{defin}

\begin{remark}
    A redex is associated to two degrees, one as a redex and another as a term. Since a redex $r$ may contain other redexes we have that $\partial (r) \le d(r)$. It should be noted we have defined degree to mean 3 different things here, but as long as we are careful we should not get confused.
\end{remark}

% partial T < partial r
\begin{lemma}\label{beta_redex_ineq}
    If $r$ is a redex of type $T$ then $\partial(T) < \partial_{\beta}(r)$. 
\end{lemma}

\begin{proof}
    Checking the cases for $r$:
    \begin{itemize}
        \item $\partial (T) < \partial_{\beta}(\fst(t, u)) = \max(\partial(T), \partial(U)) + 1$.
        \item $\partial (T) < \partial_{\beta}(\snd(u, t)) = \max(\partial(U), \partial(T)) + 1$.
        \item $\partial (T) < \partial_{\beta}((\lambda x . t)u) = \max(\partial(U), \partial(T)) + 1$.
    \end{itemize}
\end{proof}

% substitution inequality
\begin{lemma}\label{beta_sub_ineq}
    If $\Gamma , x : T \vdash t \Leftarrow U$ then $d_{\beta}(t[u/x]) \leq \max(d_{\beta}(t), d_{\beta}(u), \partial(T))$.
\end{lemma}

\begin{proof}
    Analysing the redexes of $t[u/x]$ we find that they fall into the following cases:
    \begin{itemize}
        \item They are redexes of $t$ (in which $u$ has become $x$).
        \item They are redexes of $u$, proliferating due to each occurrence of $x$ in $t$.
        \item They are formed when $t$ is of the form $\fst(x)$, $\snd(x)$, or $x v$ for $u$ of the form $(u', u'')$, $(u', u'')$, or $\lambda y . u'$ respectively. These new redexes have degree $\partial(T)$.
    \end{itemize}
\end{proof}

% reduction inequality
\begin{lemma}\label{beta_reduct_ineq}
    If $t \to_{\beta} u$ then $d_{\beta}(u) \le d_{\beta}(t)$.    
\end{lemma}

\begin{proof}
    Consider the reduction where $u$ is obtained from $t$ by replacing the redex $r$ in $u$ by $c$. Now we consider all the redexes of $u$ where we find:
    \begin{itemize}
        \item redexes which were originally in $t$, but not in $r$, and have been modified by the replacement of $r$ by $c$. Observe that their degree does not change.
        \item redexes which were originally in $c$. But $c$ is obtained by reducing $r$, or in other words a substitution in $r$. Notice $(\lambda x . s)s'$ becomes $s[s'/x]$ and Lemma \ref{beta_sub_ineq} tells us that $d_{\beta}(c) \le \max(d_{\beta}(s), d_{\beta}(s'), \partial(T))$, where $T$ is the type of $x$. But by Lemma \ref{beta_redex_ineq} we have $\partial (T) \le \partial (r)$. Applying $\max$ gives us $\max(d(s), d(s'), \partial(T)) \le \max(d_{\beta}(s), d_{\beta}(s'), \partial_{\beta}(r))$ and hence $d_{\beta}(c) \le \max(d_{\beta}(s), d_{\beta}(s'), \partial(r))=d(r)$.
        \item redexes which come from replacing $r$ by $c$. These redexes have degree equal to $\partial(T)$ where $T$ is the type of $r$. By Lemma \ref{beta_redex_ineq} we have $\partial(T) \le \partial (r)$.
    \end{itemize}
\end{proof}

Next we will prove a lemma bounding the number of redexes of a certain degree.

% number of redexes inequality
\begin{lemma}\label{beta_redex_number_ineq}
    Let $r$ be a redex of maximal degree $n$ in $t$, and suppose that all redexes strictly contained in $r$ have degree less than $n$. If $u$ is obtained from $t$ by reducing $r$ to $c$. Then $u$ has strictly fewer redexes of degree $n$.
\end{lemma}

\begin{proof}
    When the reduction happens we make the following observations:
    \begin{itemize}
        \item The redexes outside $r$ in $t$ remain $u$.
        \item The redexes strictly inside $r$ are in general conserved but sometimes become more prolific. Take for example $(\lambda x . (x, x)) s \to_{\beta} (s, s)$. The number of redexes in the reduct are double that of redex on the left. However the degree of the proliferated redexes must be strictly less than $n$.
        \item The redex $r$ is destroyed and possibly replaced by redexes of strictly smaller degree.
    \end{itemize}
\end{proof}

\begin{remark}
    Although not defined, we take the meaning of \emph{a redex strictly inside} to be a redex that is not the whole redex.
\end{remark}

We now have all the machinery needed to prove that typed terms in the STLC are strongly $\beta$-normalising.

% Every term is beta normalising
\begin{theorem}\label{beta_SN}
    Every derivable term $\Gamma \vdash t \Leftarrow A$ in the STLC is strongly $\beta$-normalising.
\end{theorem}

\begin{proof}
    Consider the function $\mu : \Term \to \N \times \N$ which takes $t \mapsto (n, m)$ where $n = d_{\beta}(t)$ and $m$ is the number of redexes in $t$ of degree $n$. By Lemma \ref{beta_redex_number_ineq} it is possible to choose a redex $r$ of $t$ in such a way that, after reduction of $r$ to $c$, the reduct $t'$ satisfies $\mu(t') < \mu(t)$. Thus by double induction on $n$ and $m$ it is possible to see that $\mu(t)$ can always be decreased until $t$ is normal.
\end{proof}

\begin{remark}
    The ordering in $\mu(t') < \mu(t)$ on $\N \times \N $ is the lexicographic ordering. Meaning $(n', m') < (n, m)$ if and only if $n' < n$ or $n'=n$ and $m' < m$. (Think Alphabetical order).
\end{remark}

\begin{remark}
    Since we have decreasing sequences of natural numbers we must have a finite number of reductions in \emph{any} reduction sequence. Of course we have weakly normalising too.
\end{remark}

% Coherence lemma
\begin{lemma}\label{beta_coh}
    Suppose $\Gamma \vdash M \Leftarrow T$ and $M \twoheadrightarrow_{\beta} N$, then $\Gamma \vdash M \equiv N : T$.
\end{lemma}

\begin{proof}
    We will only sketch the proof here. It will require inducting over syntax and the definition of $\twoheadrightarrow_\beta$. The main part to notice is that as $\to_\beta$ is a compatible relation, we can destruct the syntax down and isolate a redex. Then using ($\to$-$\beta$), ($\times$-$\beta_1$) and ($\times$-$\beta_2$) we can combine their results with congruence rules to build the term back up. It will be a technically finicky proof.
\end{proof}

\begin{remark}
    Although we haven't checked Lemma \ref{beta_coh}, it would be extremely surprising if it were false. So we have a strong feeling that it ought to be true. 
\end{remark}

We now wish to prove that $\to_\beta$ is weakly Church-Rosser. First we take some results from Takahashi \cite{TakahashiM1989PRIL, Takahashi:1995:PR9:207177.207191}, who considers \emph{parallel reductions}. This is a stronger relation than $\to_{\beta}$ and weaker than $\twoheadrightarrow_{\beta}$. This might not seem like much but, parallel ($\beta$-)reduction, denoted $\Rightarrow_{\beta}$ (not to be confused with our typing judgements), satisfies the diamond in Church-Rosser. And since $\twoheadrightarrow_{\beta}$ is the transitive closure of $\Rightarrow_{\beta}$, it too satisfies the diamond in Church-Rosser hence $\to_{\beta}$ has the Church-Rosser property. We will formalise this argument as follows and consider $\beta$, $\eta$ and $\beta \eta$ reductions along the way.

% Parallel beta reduction
\begin{defin}
    \emph{Parallel $\beta$-reduction}, $\Rightarrow_{\beta}$, is defined inductively on terms by the following rules:
    \begin{enumerate}
        \item $x \Rightarrow_{\beta} x$ for a variable or constant $x$.
        \item $\lambda x . M \Rightarrow_{\beta} \lambda x . M'$ if $M \Rightarrow_{\beta} M'$.
        \item $MN \Rightarrow_{\beta} M' N'$ if $M \Rightarrow_{\beta} M'$ and $N \Rightarrow_{\beta} N'$.
        \item $(M, N) \Rightarrow_{\beta} (M', N')$ if $M \Rightarrow_{\beta} M'$ and $N \Rightarrow_{\beta} N'$.
        \item $(\lambda x . M)N \Rightarrow_{\beta} M'[N' / x]$ if $M \Rightarrow_{\beta} M'$ and $N \Rightarrow_{\beta} N'$.
        \item $\fst(M, N) \Rightarrow_{\beta} M'$ if $M \Rightarrow_{\beta} M'$.
        \item $\snd(M, N) \Rightarrow_{\beta} N'$ if $N \Rightarrow_{\beta} N'$.
    \end{enumerate}
\end{defin}

\begin{remark}
    If we expand the definition of compatible in the definition of $\to_{\beta}$ it may appear to be identical to the definition of $\Rightarrow_{\beta}$. The key difference is the direction in which we are building up the terms. In the above definition we are breaking down the syntax and making sure that \emph{all} components also satisfy the relation. We will see later the relation with $\to_{\beta}$.
\end{remark}

\begin{remark}
    The name comes from the fact that parallel reduction can reduce many $\beta$-redexes at once, unlike usual reduction.
\end{remark}

% => beta is reflexive
\begin{cor}\label{beta_par_refl}
    The relation $\Rightarrow_\beta$ is reflexive.
\end{cor}

\begin{proof}
    Observe that ignoring the last three rules in the definition of $\Rightarrow_\beta$ we still cover all the syntax.
\end{proof}

The following lemma shows the strengths of our notions of $\beta$-reduction. It will be very useful later on.

% M -> M'  ==>  M => M'  ==>  M ->> M'
\begin{lemma}\label{beta_par_imp}
    We have the following implications:
    $$
        M \to_\beta M' \quad \implies \quad M \Rightarrow_\beta M' \quad \implies \quad M \twoheadrightarrow_\beta M'
    $$
\end{lemma}

\begin{proof}
    For the first implication, observe that a redex in $M$ is being contracted to such that $M \to_\beta M'$. We can also contract the redex in the definition of $M \Rightarrow_\beta M'$ by choosing the correct rule. For the second implication, proceed by induction on $M$:
    \begin{itemize}
        \item If $M = x \Rightarrow_\beta M'$ then clearly $M'=x$ hence $x \twoheadrightarrow x$.
        \item If $M = \lambda x . N$ then $M' = \lambda x . N'$ where $N \Rightarrow_\beta N'$, which by the induction hypothesis gives us $N \twoheadrightarrow_\beta N'$, and since $\twoheadrightarrow_\beta$ is the transitive, reflexive closure of a compatible relation, we have $M \twoheadrightarrow_\beta M'$.
        \item If $M = (a, b)$, then by induction hypothesis and $\twoheadrightarrow_\beta$ being compatible we have $M \twoheadrightarrow_\beta M'$.
        \item Finally for the case that $M$ is a $\beta$-redex, observe that $\twoheadrightarrow_\beta$ can reduce this redex, and by the induction hypothesis and subredexes of that.
    \end{itemize}
\end{proof}

\begin{remark}
    The previous proof may be considered as a sketch since we didn't explicitly check every case. This can definitely be done but it is not so interesting.
\end{remark}

We can now discuss \emph{the complete ($\beta$-)development of a term}. This is a way of completely reducing down \emph{all} $\beta$-redexes at once.

\begin{defin}
    The \emph{complete ($\beta$-)development} of a term $\Gamma \vdash t \Leftarrow A$, written $t^*$ is defined by induction on syntax:
    \begin{itemize}
        \item For a variable or constant $x^* = x$.
        \item $(\lambda x . M)^* = \lambda x . M^*$.
        \item $(M N)^* = M^* N^*$ if $MN$ is not a $\beta$-redex.
        \item $(a, b)^* = (a^*, b^*)$.
        \item $((\lambda x . M)N)^* = M^* [N^* / x]$.
        \item $(\fst (a, b))^* = a^*$.
        \item $(\snd (a, b))^* = b^*$.
    \end{itemize}
\end{defin}

\begin{lemma}
    Given a term $\Gamma \vdash t \Leftarrow A$, $t^*$ is in $\beta$-normal form.
\end{lemma}

\begin{proof}
    Observe by induction that the complete development rids a term of \emph{all} $\beta$-redexes.
\end{proof}


Here is a technical lemma that is the driving force behind our proof of being Church-Rosser. It says that the complete development is always the most reduced form of a term.

\begin{lemma}\label{cd_lemma_beta}
    Suppose $M \Rightarrow_\beta N$ then $N \Rightarrow_\beta M^*$.
\end{lemma}

\begin{proof}
    We proceed by induction on $M \Rightarrow_\beta N$:
    \begin{itemize}
        \item Suppose $M = x$ then $M = x \Rightarrow_\beta x = N$. Hence $N = x \Rightarrow_\beta x^* = M^*$.
        \item Suppose $M = \lambda x . t \Rightarrow_\beta \lambda x . t'$. Then $t \Rightarrow_\beta t'$ and $t' \Rightarrow_\beta t^*$ by the induction hypothesis, hence $N = \lambda x . t' \Rightarrow_\beta \lambda x . t^* = (\lambda x . t)^* = M^*$.
        \item Suppose $M = a b$ and $M$ is not a $\beta$-redex, then $M = a b \Rightarrow_\beta a ' b ' = N$, with $a \Rightarrow_\beta a'$ and $b \Rightarrow_\beta b'$. Then by the induction hypotheses, we have $a' \Rightarrow_\beta a^*$ and $b' \Rightarrow_\beta b^*$, yielding $a' b' \Rightarrow_\beta a^* b^* = (a b)^*=M^*$, since $M$ is not a $\beta$-redex.
        \item Suppose $M = (a, b) \Rightarrow_\beta (a' , b')$ where $a \Rightarrow_\beta a'$ and $b \Rightarrow_\beta b'$. Then by the induction hypotheses we have $a' \Rightarrow_\beta a^*$ and $b' \Rightarrow_\beta b^*$. Hence $N = (a', b') \Rightarrow_\beta (a^*, b^*) = (a, b)^* = M^*$.
        \item Suppose $M = (\lambda x . y) t \Rightarrow_\beta y'[t'/x]$ with $y \Rightarrow_\beta y'$ and $t \Rightarrow_\beta t'$. By our induction hypotheses: $y' \Rightarrow_\beta y^*$ and $t' \Rightarrow_\beta t^*$. It can be shown by induction on the syntax of $y'$ that $y'[t'/x] \Rightarrow_\beta y^*[t^* / x]$ however the proof would get to long. Assuming this we have $y' [t'/x] \Rightarrow_\beta y^*[t^* / x] = (y[t/x])^*$, again by induction on $y$ and $t$, and again we omit since it would lengthen the proof substantially, finally giving us $N \Rightarrow_\beta M^*$.
        \item Finally suppose $M = \fst(a, b) \Rightarrow_\beta a'$ where $a \Rightarrow_\beta a'$, by our induction hypothesis, $a' \Rightarrow_\beta a^*$ so $N = a' \Rightarrow_\beta a^* = (\fst(a, b))^* = M^*$.
        \item The case for $\snd$ is very similar to the case for $\fst$.
    \end{itemize}
\end{proof}

Now we show that $\Rightarrow_\beta$ satisfies a diamond property.

\begin{cor}\label{diamond_par_beta}
    Given $M \Rightarrow_\beta N_1$ and $M \Rightarrow_\beta N_2$ then $N_1 \Rightarrow_\beta M'$ and $N_2 \Rightarrow_\beta M'$ for some $M'$.
\end{cor}

\begin{proof}
    By Lemma \ref{cd_lemma_beta} we observe that $M' = M^*$ gives us the desired result.
\end{proof}

We now have all we need to prove our desired result.

\begin{lemma}\label{beta_WCR}
    $\beta$-reduction is weakly Church-Rosser.
\end{lemma}

\begin{proof}
    Given $a \to_\beta b$ and $a \to_\beta b'$ we see that by Lemma \ref{beta_par_imp}, we have $a \Rightarrow_\beta b$ and $a \Rightarrow_\beta b'$. Hence by the diamond property of $\Rightarrow_\beta$ (Corollary \ref{diamond_par_beta}), we have $b \Rightarrow_\beta a'$ and $b' \Rightarrow_\beta a'$ for some $a'$. Which by Lemma \ref{beta_par_imp} again, gives us $b \twoheadrightarrow_\beta a'$ and $b' \twoheadrightarrow_\beta a'$.
\end{proof}

\begin{theorem}
    $\beta$-reduction is Church-Rosser (on well-typed terms).
\end{theorem}

\begin{proof}
    $\beta$-reduction is strongly normalising by Lemma \ref{beta_SN} and weakly Church-Rosser by Lemma \ref{beta_WCR}. Hence by Newman's Lemma (\ref{newman}) we have that $\beta$-reduction is Church-Rosser. 
\end{proof}

\begin{remark}
    In \cite{Takahashi:1995:PR9:207177.207191, barendregt1984lambda} it is stated that the diamond property of $\Rightarrow_\beta$ (Lemma \ref{diamond_par_beta}) directly implies that $\to_\beta$ is Church-Rosser. We could not understand how this implication has come about, so we instead use Newman's lemma.
\end{remark}


%%
%%  Eta reduction
%%

\subsection{ \texorpdfstring{$\eta$}{}-reduction}

The proof of Church-Rosser for $\eta$-reduction will be simpler than that of $\beta$-reduction. This is because reduced $\eta$-redexes have comparably tame behaviour and don't product any new redexes.

% Define eta reduction
\begin{defin}
    We define \emph{$\eta$-reduction} to be the least compatible relation $\to_{\eta}$ on $\mathrm{Term}$ satisfying the following conditions:
    \begin{enumerate}
        \item $\lambda x . f x \to_{\eta} f$
        \item $(\fst(t), \snd(t)) \to_{\eta} t$
    \end{enumerate}
    Just like for $\beta$-reduction we have the notions of \emph{$\eta$-redex} and terms that \emph{arise by contracting the redex}.
\end{defin}

% Define eta normal form
\begin{defin}
    A term is said to be in \emph{$\eta$-normal form} if it is in normal form with respect to $\to_{\eta}$.
\end{defin}

% Define multi-step eta reductions
\begin{defin}
    Let $\twoheadrightarrow_{\eta}$ be the transitive, reflexive closure of $\to_{\eta}$ called a \emph{multi-step $\eta$-reduction}.
\end{defin}

We will now show that $\to_\eta$ is strongly normalising.

\begin{remark}
    Originally we had thought to modify the proof of $\beta$-normal\-isa\-tion, and make it work for $\eta$. However, this is where the difference between the two is key.
    $\beta$-normal\-isa\-tion has the power to create new $\beta$-redexes whereas $\eta$-normalisation never does. In fact $\eta$-normalisation is strongly normalising even in the untyped lambda calculus. This suggests that talking about degrees is not the correct approach and there ought to be some other metric for which can be used to bound $\eta$-reducible terms. Based off of work in \cite{Fortune1983}, the authors of \cite[Ex. 3.21]{Sorensen} define a \emph{depth} function for terms. We believe this to be the actual depth of the underlying tree of the abstract binding tree of the syntax of the term. But that is not a relevant result for now.
\end{remark}

\begin{defin}
    Given a term $t$ we define the \emph{depth $\mathsf{\delta(t)}$ of $t$} by induction on terms:
    \begin{itemize}
        \item $\delta (x):=0$ for $x$ a variable or constant.
        \item $\delta (a b) := 1+ \max(\delta(a), \delta(b))$.
        \item $\delta (\lambda x . y):= 1 + \delta(y)$.
        \item $\delta ((a, b)) := 1 + \max(\delta(a), \delta(b))$.  
    \end{itemize}
\end{defin}

% eta bounds
\begin{lemma}\label{eta_red_bound}
    If $t \to_{\eta} u$ then $\delta(u) < \delta(t)$.
\end{lemma}

\begin{proof}
    Observe that since $\to_{\eta}$ is a compatible relation, we need only prove the statement for a redex. We do this by cases:
    \begin{itemize}
        \item
        $$
            \begin{aligned}
                \delta ((\fst(s), \snd(s))) &= 1+ \max(\delta(\fst(s)), \delta(\snd(s))) \\
                &= 1 + \max(1+ \delta(s), 1+ \delta(s)) \\
                &= \delta(s)+ 2
            \end{aligned}
        $$
        \item
        $$
            \begin{aligned}
                \delta (\lambda x . s x) &= 1 + \delta(s x) \\
                &= 2 + \max(\delta(s), \delta(x)) \\
                &= \delta(s) + 2
            \end{aligned}
        $$
    \end{itemize}
    Observe that in both cases we have that the depth of a redex $s$ is $\delta(s) = \delta(r) + 2$ where $r$ is the reduct of $s$. However at the level of terms we cannot guarantee equality due to the nature of depth and compatibility. 
\end{proof}

\begin{lemma}\label{eta_SN}
    $\eta$-reduction is strongly normalising.
\end{lemma}

\begin{proof}
    By Lemma \ref{eta_red_bound} we have that the depth of any $\eta$-reduction sequence is strictly decreasing. Hence there may only be finitely many steps in any given $\eta$-reduction sequence.
\end{proof}

% Coherence lemma
\begin{lemma}\label{eta_coh}
    Suppose $\Gamma \vdash M \Leftarrow T$ and $M \twoheadrightarrow_{\eta} N$, then $\Gamma \vdash M \equiv N : T$.
\end{lemma}

\begin{proof}
    The proof ought to be similar to the sketch outlined in Lemma \ref{beta_coh}.
\end{proof}

Now we define a notion of \emph{parallel}

% parallel eta reductions
\begin{defin}\label{eta_par}
    \emph{Parallel $\eta$-reduction}, $\Rightarrow_\eta$, is defined inductively on terms by the following rules:
    \begin{enumerate}
        \item $x \Rightarrow_\eta x$ for a variable or constant $x$.
        \item $\lambda x . M \Rightarrow_\eta \lambda x . M'$ if $M \Rightarrow_\eta M'$.
        \item $M N \Rightarrow_\eta M' N'$ if $M \Rightarrow_\eta M'$ and $N \Rightarrow_\eta N'$.
        \item $(M, N) \Rightarrow_\eta (M', N')$ if $M \Rightarrow_\eta M'$ and $N \Rightarrow_\eta N'$.
        \item $\lambda x . M x \Rightarrow_\eta M'$ if $M \Rightarrow_\eta M'$ and $x \not\in \mathrm{FV}(M)$.
        \item $(\fst(t), \snd(t)) \Rightarrow_\eta t'$ if $t \Rightarrow_\eta t'$.
    \end{enumerate}
\end{defin}

\begin{remark}
    Notice the condition on $\lambda x . M x$ we have to check that $M$ is specifically not ``in scope'' of $x$. Since $M$ on it's own does not make sense otherwise.
\end{remark}

\begin{cor}
    The relation $\Rightarrow_\eta$ is reflexive.
\end{cor}

\begin{proof}
    Observe that ignoring the last two rules, still qualifies any term $t$ to satisfy $t \Rightarrow_\eta t$.
\end{proof}

Now we show the strength of $\Rightarrow_\eta$ relative to the other two $\eta$-reduction relations.

\begin{lemma}\label{eta_par_imp}
    We have the following implications:
    $$
        M \to_\eta M' \quad \implies \quad M \Rightarrow_\eta M' \quad \implies \quad M \twoheadrightarrow_\eta M'
    $$
\end{lemma}

\begin{proof}
    This first implication is trivial. The second implication can be done by induction on $M$ and the definition of $M \Rightarrow_\eta M'$.
\end{proof}

Now we define a way of completely reducing all $\eta$-redexes of a term.

\begin{defin}
    The \emph{complete ($\eta$-)development} of a term $t$, written $t^*$ is defined by induction on syntax:
    \begin{itemize}
        \item For a variable or constant $x^* = x$.
        \item $(\lambda x . M)^* = \lambda x . M^*$ if $\lambda x . M$ is not an $\eta$-redex.
        \item $(M N)^* = M^* N^*$.
        \item $(a, b)^* = (a^*, b^*)$ if $(a, b)$ is not an $\eta$-redex.
        \item $(\lambda x . M x)^* = M^*$ if $x \not\in \mathrm{FV}(M)$.
        \item $(\fst(t), \snd(t))^* = t^*$.
    \end{itemize}
\end{defin}

\begin{remark}
    We have overloaded the notation $t^*$ but since this section is only concerned with $\eta$-reduction this is fine.
\end{remark}

\begin{remark}
    Notice we have not mentioned any typing information about $t$. $\eta$-reduction is quite strong even without the presence of types.
\end{remark}

\begin{lemma}\label{cd_eta_normal}
    Given a term $t$, $t^*$ is in $\eta$-normal form.
\end{lemma}

\begin{proof}
    Observe by induction that the complete development rids a term of \emph{all} $\eta$-redexes.
\end{proof}

Now for the technical lemma that will give us Church-Rosser.

\begin{lemma}\label{cd_lemma_eta}
    Suppose $M \Rightarrow_\eta N$ then $N \Rightarrow_\eta M^*$.
\end{lemma}

\begin{proof}
    Begin by induction on $M \Rightarrow_\eta N$:
    \begin{itemize}
        \item If $M = x$, then $x \Rightarrow_\eta N$ so $N  = x \Rightarrow_\eta x = M^*$.
        \item If $M = \lambda x . t$ and $M$ is not an $\eta$-redex, then $M - \lambda x . t \Rightarrow_\eta \lambda x . t' = N$. By definition $t \Rightarrow_\eta t'$, and by the induction hypothesis $t' \Rightarrow_\eta t^*$. Hence $N = \lambda x . t' \Rightarrow_\eta \lambda x . t^* = (\lambda x. t)^*$ since $(\lambda x . t)$ is not an $\eta$-redex.
        \item If $M = a b \Rightarrow_\eta a' b' = N$. By definition $a \Rightarrow_\eta a'$ and $b \Rightarrow_\eta b'$. By the induction hypotheses $a' \Rightarrow_\eta a^*$ and $b' \Rightarrow_\eta b^*$. Hence $N = a'b' \Rightarrow_\eta a^* b^* = (a b)^* = M^*$.
        \item If $M = (a, b)$ and $(a, b)$ is not an $\eta$-redex, then $M = (a, b) \Rightarrow_\eta (a', b') = N$. By definition $a \Rightarrow_\eta a'$ and $b \Rightarrow_\eta b'$. By the induction hypotheses $a' \Rightarrow_\eta a^*$ and $b' \Rightarrow_\eta b^*$. Hence $N = (a',b') \Rightarrow_\eta (a^*, b^*) = (a, b)^* = M^*$ since $(a, b)$ is not an $\eta$-redex.
        \item If $M = \lambda x . t x$ for $x \not\in \mathrm{FV}(t)$, then $M = \lambda x . t x \Rightarrow_\eta N$. There are two cases for $N$:
        \begin{itemize}
            \item If $N = t'$ for some $t \Rightarrow_\eta t'$ then $M^* = (t')^*$ and hence $N = t' \Rightarrow_\eta t^* = M^*$.
            \item If $N = \lambda x . t' x$ for some $t x\Rightarrow_\eta t' x$ then our induction hypothesis gives $t' x \Rightarrow_\eta (t x)^* = t^* x$. Hence $t' \Rightarrow_\eta t^*$. Thus by definition we have $\lambda x . t' x \Rightarrow_\eta t^*$ since $t' \Rightarrow_\eta t^*$. The induction here is a bit tricky and would probably benefit with some clearer notation. 
        \end{itemize}
        \item Finally if $M =(\fst(t), \snd(t)) \Rightarrow_\eta N$ then we have two cases for $N$:
        \begin{itemize}
            \item If $N = t'$ for some $t \Rightarrow_\eta t'$, then by the induction hypothesis $t' \Rightarrow_\eta t^* = (\fst(t), \snd(t))^* = M^*$.
            \item If $N = ((\fst(t'), \snd(t'))$ for some $t \Rightarrow_\eta t'$, then by the induction hypothesis $t' \Rightarrow_\eta t^*$.
            Hence by definition we have $((\fst(t'), \snd(t')) \Rightarrow_\eta t^*$ since $t' \Rightarrow_\eta t^*$.
        \end{itemize}
    \end{itemize}
\end{proof}


Now we show that $\Rightarrow_\eta$ satisfies a diamond property.

\begin{cor}\label{diamond_par_eta}
    Given $M \Rightarrow_\eta N_1$ and $M \Rightarrow_\eta N_2$ then $N_1 \Rightarrow_\eta M'$ and $N_2 \Rightarrow_\eta M'$ for some $M'$.
\end{cor}

\begin{proof}
    By Lemma \ref{cd_lemma_eta} we observe that $M' = M^*$ gives us the desired result.
\end{proof}

We now have all we need to prove our desired result.

\begin{lemma}\label{eta_WCR}
    $\eta$-reduction is weakly Church-Rosser.
\end{lemma}

\begin{proof}
    Given $a \to_\eta b$ and $a \to_\eta b'$ we see that by Lemma \ref{eta_par_imp}, we have $a \Rightarrow_\eta b$ and $a \Rightarrow_\eta b'$. Hence by the diamond property of $\Rightarrow_\eta$ (Corollary \ref{diamond_par_eta}), we have $b \Rightarrow_\eta a'$ and $b' \Rightarrow_\eta a'$ for some $a'$. Which by Lemma \ref{eta_par_imp} again, gives us $b \twoheadrightarrow_\eta a'$ and $b' \twoheadrightarrow_\eta a'$.
\end{proof}

\begin{theorem}
    $\eta$-reduction is Church-Rosser.
\end{theorem}

\begin{proof}
    $\eta$-reduction is strongly normalising by Lemma \ref{eta_SN} and weakly Church-Rosser by Lemma \ref{eta_WCR}. Hence by Newman's Lemma (\ref{newman}) we have that $\eta$-reduction is Church-Rosser. 
\end{proof}

\begin{remark}
    Notice yet again how we at no point used the typing of terms for $\eta$.
\end{remark}

\begin{remark}
    $\eta$-reduction is typically seen as an easy case and it is not so common to see proofs written out explicitly for it. Lemma \ref{cd_lemma_eta} for example is not such an easy proof to write or read. This is due to the iterated uses of induction. One way to make this easier to check is to use a proof assistant. This however would take some time to set up properly, and may risk diverging our attention.
\end{remark}


%%
%%  Beta eta reduction
%%

\subsection{\texorpdfstring{$\beta \eta$}-reduction}

We now begin the intricate business of mixing the two reductions, keeping note of how they interact, and finally showing that, used together, they satisfy Church-Rosser.

\begin{defin}
    We define \emph{$\beta\eta$-reduction}, $\to_{\beta\eta}$ to be the union of the relations $\to_\beta$ and $\to_\eta$.
\end{defin}

\begin{remark}
    Observe that $\to_{\beta\eta}$ is also a compatible relation.
\end{remark}

\begin{defin}
    We define $\twoheadrightarrow_{\beta\eta}$ as the transitive, reflexive closure of $\to_{\beta\eta}$.
\end{defin}

\begin{lemma}\label{beta_SN_iff_beta_eta_SN}
    A term $\Gamma \vdash t \Leftarrow A$ has a $\beta$-normal form if and only if it has a $\beta \eta$-normal form.
\end{lemma}

\begin{proof}
    A similar proof can be found in \cite[Corollary 15.1.5]{barendregt1984lambda}, this would of course have to be modified to accommodate for product types. The idea of the proof is to show that $M \twoheadrightarrow_{\beta\eta} N$ implies $M \twoheadrightarrow_{\beta} P \twoheadrightarrow_{\eta} N$ for some $P$. Then since $\eta$-reduction is strongly normalising, it must be the case that $\beta$-reduction is strongly normalising if and only if $\beta \eta$-reduction is.
\end{proof}

\begin{cor}\label{beta_eta_SN}
    $\beta \eta$-reduction is strongly normalising on typed terms.
\end{cor}

\begin{proof}
    By Lemma \ref{beta_SN} and Lemma \ref{beta_SN_iff_beta_eta_SN}.
\end{proof}

Next we introduce parallel $\beta \eta$-reduction.

\begin{defin}
    \emph{Parallel $\beta\eta$-reduction}, $\Rightarrow_{\beta\eta}$, is defined inductively on terms by the following rules:
    \begin{enumerate}
        \item $x \Rightarrow_{\beta\eta} x$ for a variable or constant $x$.
        \item $\lambda x . M \Rightarrow_{\beta\eta} \lambda x . M'$ if $M \Rightarrow_{\beta\eta} M'$.
        \item $M N \Rightarrow_{\beta\eta} M' N'$ if $M \Rightarrow_{\beta\eta} M'$ and $N \Rightarrow_{\beta\eta} N'$.
        \item $(M, N) \Rightarrow_{\beta\eta} (M', N')$ if $M \Rightarrow_{\beta\eta} M'$ and $N \Rightarrow_{\beta\eta} N'$.
        \item $(\lambda x . M) N \Rightarrow_{\beta\eta} M '[N'/x]$ if $M \Rightarrow_{\beta\eta} M'$ and $N \Rightarrow_{\beta\eta} N'$.
        \item $\fst(M, N) \Rightarrow_{\beta\eta} M'$ if $M \Rightarrow_{\beta\eta} M'$.
        \item $\snd(M, N) \Rightarrow_{\beta\eta} N'$ if $N \Rightarrow_{\beta\eta} N'$.
        \item $\lambda x . M x \Rightarrow_{\beta\eta}M'$ if $M \Rightarrow_{\beta\eta} M'$ and $x \not \in \mathrm{FV}(M)$.
        \item $(\fst (t), \snd(t)) \Rightarrow_{\beta\eta} t'$ if $t \Rightarrow_{\beta\eta} t'$.
    \end{enumerate}
\end{defin}

\begin{cor}\label{beta_eta_par_refl}
    $\Rightarrow_{\beta\eta}$ is reflexive.
\end{cor}

\begin{proof}
    Observe that any term can be put through the definition of $\Rightarrow_{\beta\eta}$ even by ignoring the last five cases.
\end{proof}

Next we give the technical lemma that will let us prove Church-Rosser.

\begin{lemma}\label{beta_eta_par_imp}
    We have the following implications:
    $$
        M \to_{\beta\eta} M' \quad \implies \quad M \Rightarrow_{\beta\eta} M' \quad \implies \quad M \twoheadrightarrow_{\beta\eta} M'
    $$
\end{lemma}

\begin{proof}
    This first implication is trivial. The second implication can be done by induction on $M$ and the definition of $M \Rightarrow_{\beta\eta} M'$.
\end{proof}

Now we need a way of fully $\beta \eta$-reducing a term.

\begin{defin}
    The \emph{complete ($\beta\eta$-)development} of a term $t$, written $t^*$ is defined by induction on syntax:
    \begin{itemize}
        \item For a variable or constant $x^*= x$.
        \item $(\lambda x . M)^* = \lambda x . M^*$ if $\lambda x . M$ is not an $\eta$-redex.
        \item $(M N)^* = M^* N^*$ if $MN$ is not a $\beta$-redex.
        \item $(a, b)^* = (a^*, b^*)$ if $(a, b)$ is not an $\eta$-redex.
        \item $((\lambda x . M) N)^* = M^* [N^* / x]$.
        \item $(\fst(a, b))^* = a^*$.
        \item $(\snd(a, b))^* = b^*$.
        \item $(\lambda x . M x)^* = M^*$ if $x \not \in \mathrm{FV}(M)$.
        \item $(\fst(t), \snd(t))^* = t^*$.
    \end{itemize}
\end{defin}

\begin{remark}
    We have yet again overridden the notation $t^*$. As before we keep the notion contained within the section to avoid any confusion.
\end{remark}

\begin{lemma}
    Given a term $\Gamma \vdash t \Leftarrow A$, $t^*$ is in $\beta \eta$-normal form.
\end{lemma}

\begin{proof}
    Observe that any $\beta \eta$-redexes will be reduced. This proof can be done by induction on syntax. The induction may have to go a bit deeper than just over term forms since we need to single out the cases for $\beta \eta$-redexes.
\end{proof}

Now we can prove our technical lemma that will give us Church-Rosser for $\beta\eta$.

\begin{lemma}\label{cd_lemma_beta_eta}
    Suppose $M \Rightarrow_{\beta\eta} N$, then $N \Rightarrow_{\beta\eta} M^*$.    
\end{lemma}

\begin{proof}
    We begin by induction on $M \Rightarrow_{\beta\eta} N$:
    \begin{itemize}
        \item If $M = x \Rightarrow_{\beta\eta} x = N$, then $N = x \Rightarrow_{\beta\eta} x = x^* = M^*$.
        \item If $M = \lambda x . t$ is not an $\eta$-redex, then $M = \lambda x . t \Rightarrow_{\beta\eta} \lambda x . t'$ where $t \Rightarrow_{\beta\eta} t'$, then by the induction hypothesis, $t' \Rightarrow_{\beta\eta} t^*$, hence $\lambda x . t' \Rightarrow_{\beta\eta} \lambda x . t^*=(\lambda x . t)* = M^*$ since $t$ is not an $\eta$-redex.
        \item If $M = a b$ is not a $\beta$-redex, then $M = a b \Rightarrow_{\beta\eta} a' b'$ where $a \Rightarrow_{\beta\eta} a'$ and $b \Rightarrow_{\beta\eta} b'$. By our induction hypotheses we have $a' \Rightarrow_{\beta\eta} a^*$ and $b' \Rightarrow_{\beta\eta} b^*$, hence $a' b' \Rightarrow_{\beta\eta} a^* b^* = (ab)^* = M^*$ since $ab$ is not a $\beta$-redex.
        \item If $M = (a, b)$ is not an $\eta$-redex, then $M = (a, b) \Rightarrow_{\beta\eta} (a', b')$ where $a \Rightarrow_{\beta\eta} a'$ and $b \Rightarrow_{\beta\eta} b'$. By our induction hypotheses we have $a' \Rightarrow_{\beta\eta} a^*$ and $b' \Rightarrow_{\beta\eta} b^*$, hence $(a', b') \Rightarrow_{\beta\eta} (a^*, b^*) = (a, b)^* = M^*$ since $(a, b)$ is not an $\eta$-redex.
        \item If $M = (\lambda x . y)t \Rightarrow_{\beta\eta} N$, by induction on $N$:
        \begin{itemize}
            \item If $N = y'[t'/x]$ where $y \Rightarrow_{\beta\eta} y'$ and $t \Rightarrow_{\beta\eta} t'$. By our induction hypotheses, we have $y' \Rightarrow_{\beta\eta} y^*$ and $t' \Rightarrow_{\beta\eta}t^*$. By induction on $y'$ and $t'$ it can be shown that $N = y'[t'/x] \Rightarrow_{\beta\eta} y^*[t^*/x]=((\lambda x . y)t)^* = M^*$.
            \item If $N = (\lambda x . y')t'$ where $y \Rightarrow_{\beta\eta} y'$ and $y \Rightarrow_{\beta\eta} t'$. By the our induction hypotheses, we have $y' \Rightarrow_{\beta\eta} y^*$ and $t' \Rightarrow_{\beta\eta} t^*$. Hence $N = (\lambda x . y')t' \Rightarrow_{\beta\eta} y^*[t^*/x] = ((\lambda x . M)t)^* = M^*$.
        \end{itemize}
        \item If $M = \fst(a, b) \Rightarrow_{\beta\eta} N$, by induction on $N$:
        \begin{itemize}
            \item If $N= a'$ where $a \Rightarrow_{\beta\eta} a'$, then by our induction hypothesis, $a' \Rightarrow_{\beta\eta} a^*$, hence $N = a' \Rightarrow_{\beta\eta} a^* = (\fst(a, b))^* = M^*$.
            \item If $N = \fst(a', b')$ where $a \Rightarrow_{\beta\eta} a'$ and $b \Rightarrow_{\beta\eta} b'$. Then $\fst(a', b') \Rightarrow_{\beta\eta} a^* = (\fst(a, b))^* = M^*$ since $a' \Rightarrow_{\beta\eta} a^*$ by our induction hypothesis.
        \end{itemize}
        \item If $M = \snd(a, b) \Rightarrow_{\beta\eta} N$, by induction on $N$:
        \begin{itemize}
            \item If $N= b'$ where $b \Rightarrow_{\beta\eta} b'$, then by our induction hypothesis, $b' \Rightarrow_{\beta\eta} b^*$, hence $N = b' \Rightarrow_{\beta\eta} b^* = (\snd(a, b))^* = M^*$.
            \item If $N = \snd(a', b')$ where $a \Rightarrow_{\beta\eta} a'$ and $b \Rightarrow_{\beta\eta} b'$. Then $N = \snd(a', b') \Rightarrow_{\beta\eta} b^* = (\snd(a, b))^* = M^*$ since $b' \Rightarrow_{\beta\eta} b^*$ by our induction hypothesis.
        \end{itemize}
        \item If $M = \lambda x. t x$ where $x \not \in \mathrm{FV}(t)$ then $M \Rightarrow_{\beta\eta} N$. Induction over $N$:
        \begin{itemize}
            \item If $N = t'$ where $t \Rightarrow_{\beta\eta} t'$, then by our induction hypothesis $t' \Rightarrow_{\beta\eta} t^* = (\lambda x . t x)^* = M^*$.
            \item If $N = \lambda x . t' x$ where $t \Rightarrow_{\beta\eta} t'$ and $x \not \in \mathrm{FV}(t')$. By our induction hypothesis $t' \Rightarrow_{\beta\eta} t^*$, hence $N = \lambda x . t' x \Rightarrow_{\beta\eta} t^* = (\lambda x . t x)^* = M^*$.
        \end{itemize}
        \item If $M = (\fst(t), \snd(t))$ and $M \Rightarrow_{\beta\eta} N$. By induction on $N$:
        \begin{itemize}
            \item If $N = t'$ where $t \Rightarrow_{\beta\eta} t'$, then by our induction hypothesis $t' \Rightarrow_{\beta\eta} t^*$, hence $N = t' \Rightarrow_{\beta\eta} t^* = (\fst(t), \snd(t))^* = M^*$.
            \item If $N = (\fst(t'), \snd(t'))$ where $t \Rightarrow_{\beta\eta} t'$ then by our induction hypothesis, $t' \Rightarrow_{\beta\eta} t^*$ hence $(\fst(t'), \snd(t')) \Rightarrow_{\beta\eta} t^* = (\fst (t), \snd(t))^* = M^*$.
        \end{itemize}
    \end{itemize}
\end{proof}

\begin{cor}\label{diamond_par_beta_eta}
    Given $M \Rightarrow_{\beta\eta} N_1$ and $M \Rightarrow_{\beta\eta} N_2$ then $N_1 \Rightarrow_{\beta\eta} M'$ and $N_2 \Rightarrow_{\beta\eta} M'$ for some $M'$.
\end{cor}

\begin{proof}
    By Lemma \ref{cd_lemma_beta_eta} we observe that $M' = M^*$ gives us the desired result.
\end{proof}

Now we can show that $\beta\eta$-reduction is weakly Church-Rosser.

\begin{lemma}\label{beta_eta_WCR}
    $\beta\eta$-reduction is weakly Church-Rosser.
\end{lemma}

\begin{proof}
    Given $a \to_{\beta\eta} b$ and $a \to_{\beta\eta} b'$ we see that by Lemma \ref{beta_eta_par_imp}, we have $a \Rightarrow_{\beta\eta} b$ and $a \Rightarrow_{\beta\eta} b'$. Hence by the diamond property of $\Rightarrow_{\beta\eta}$ (Corollary \ref{diamond_par_beta_eta}), we have $b \Rightarrow_{\beta\eta} a'$ and $b' \Rightarrow_{\beta\eta} a'$ for some $a'$. Which by Lemma \ref{beta_eta_par_imp} again, gives us $b \twoheadrightarrow_{\beta\eta} a'$ and $b' \twoheadrightarrow_{\beta\eta} a'$.
\end{proof}

\begin{theorem}
    $\beta\eta$-reduction is Church-Rosser (for typed terms).
\end{theorem}

\begin{proof}
    $\beta\eta$-reduction is strongly normalising by Lemma \ref{beta_eta_SN} and weakly Church-Rosser by Lemma \ref{beta_eta_WCR}. Hence by Newman's Lemma (\ref{newman}) we have that $\beta\eta$-reduction is Church-Rosser for typed terms. 
\end{proof}

\begin{comment}

%%
%% Canonicity
%%

\subsection{Canonicity}

\begin{defin}
    A term $\Gamma \vdash t \Leftarrow A$ is said to be in \emph{canonical form} if syntactically it is only built from variables in $\Gamma$ and constructors of the type $A$.
\end{defin}

\begin{remark}
    A more precise way to say this is perhaps that the derivation tree of $\Gamma \vdash t \Leftarrow A$ only consists of structural rules and introduction rules corresponding to $A$.
\end{remark}

From this we see some immediate consequences.

\begin{lemma}
    If a term $\Gamma \vdash t \Leftarrow A$ is in canonical form then it is necessarily in $\beta \eta$-normal form.
\end{lemma}

\begin{proof}
    If it was not in $\beta \eta$-normal form then it would contain some redex which would mean that the derivation of $\Gamma \vdash t \Leftarrow A$ uses ($\to$-intro). Hence $t$ cannot be in canonical form.
\end{proof}

However it is not so obvious that the converse is true:

\begin{lemma}
    If a term $\Gamma \vdash t \Leftarrow A$ is in $\beta \eta$-normal form, then it is in canonical form.
\end{lemma}

\begin{proof}
    [[TODO]]
\end{proof}



\end{comment}



\begin{comment}
%% beta eta reduction 
We next wish to show that $\beta$-normal forms occur if and only if $\beta \eta$-normal forms occur.

\begin{lemma}\label{beta_SN_beta_eta_SN}
    A term $t$ have a $\beta$-normal form if and only if it has a $\beta \eta$-normal form.
\end{lemma}

\begin{proof}
    A similar proof can be found in \cite[Corollary 15.1.5]{barendregt1984lambda}, this would of course have to be modified to accommodate for product types.
\end{proof}

\begin{remark}
    In particular this means that $\to_{\beta}$ being strongly normalising implies that $\to_{\beta \eta}$ is strongly normalising.
\end{remark}

% beta eta reduction is strongly normalising
\begin{cor}
    $\beta \eta$-reduction is strongly normalising.
\end{cor}

\begin{proof}
    By Lemma \ref{beta_SN} and Lemma \ref{beta_SN_beta_eta_SN}.
\end{proof}


\subsection{Closing remarks}

The best reference for these arguments is \cite{barendregt1984lambda}. There have been a few papers after which many of the arguments have been vastly simplified notably \cite{TakahashiM1989PRIL}. However to our knowledge there is no single account of many of these results. A possible future direction is via the use of \emph{categorical semantics}, which associate each ``type theory'' to an appropriately structured category. Typically these only model the \emph{statics} of the type theory, but there are attempts in the literature to realise the reductions as 2-cells in a \emph{bicategory}. Then a property such as Church-Rosser would be about the existence of pushouts in the Hom-category. 

\subsection{Canonicity}

\begin{defin}
    A term $\Gamma \vdash t \Leftarrow A$ is said to be in \emph{canonical form} if syntactically it is only built from variables in $\Gamma$ and constructors of the type $A$.
\end{defin}

\begin{remark}
    A more precise way to say this is perhaps that the derivation tree of $\Gamma \vdash t \Leftarrow A$ only consists of structural rules and introduction rules corresponding to $A$.
\end{remark}

From this we see some immediate consequences.

\begin{lemma}
    If a term $\Gamma \vdash t \Leftarrow A$ is in canonical form then it is necessarily in $\beta \eta$-normal form.
\end{lemma}

\begin{proof}
    If it was not in $\beta \eta$-normal form then it would contain some redex which would mean that the derivation of $\Gamma \vdash t \Leftarrow A$ uses $($\to$-intro)$. Hence $t$ cannot be in canonical form.
\end{proof}

However it is not so obvious that the converse is true:

\begin{lemma}
    If a term $\Gamma \vdash t \Leftarrow A$ is in $\beta \eta$-normal form, then it is in canonical form.
\end{lemma}

\begin{proof}
    
\end{proof}










Canonicity is a property of a type theory that ensures that a given term of a type $\Gamma \vdash t \Leftarrow T$ has a \emph{canonical form}, in that $t$ is only made up of variables from $\Gamma$ and constructors of $T$. Such a property would guarantee that 

[[These two concepts are very related, we should find some way to talk about it, including Church-Rosser]]
\end{comment}
