\section{Judgements}

We will now develop the basic formal tools to describe how our programming languages work.  We will first describe judgements and how to specify a type system. Then our first example will be the simply typed lambda calculus. We use the ideas developed in \cite{harper_2016} though these ideas are much older. [Probably tracable back to Gentzen]. [There are many more references to be included here]

\begin{defin}
    The notion of a \emph{judgement} or \emph{assertion} is a logical statement about an abt. The property or relation itself is called a \emph{judgement form}. The judgement that an object or objects have that property or stand in relation is said to be an \emph{instance} of that judgement form. A judgment form has also historically been called a \emph{predicate} and its instances called \emph{subjects}.
\end{defin}

\begin{remark}
    Typically a judgement is denoted $\mathsf{J}$. We can write $a\ \mathsf{J}$, $\mathsf{J}\ a$ to denote the judgment asserting that the judgement form $\mathsf{J}$ holds for the abt $a$. For more abts this can also be written prefix, infix, etc. This will be done for readability. Typically for an unspecified judgement, that is an instance of some judgement form, we will write $J$.
\end{remark}

\begin{defin}
    An \emph{inductive definition} of a judgement form consists of a collection of rules of the form
    
    $$\frac
        {J_1 \quad \cdots \quad J_k}
        {J}
    $$
    
    in which $J$ and $J_1, \dots , J_k$ are all judgements of the form being defined. THe judgements above the horizontal line are called the \emph{preimises} of the rules, and the judgement below the line is called its \emph{conclusion}. A rule with no premises is called an \emph{axiom}.
\end{defin}

\subsection{Inference rules}

\begin{remark}
    An inference rule is read as starting that the premises are \emph{sufficient} for the conclusion: to show $J$, it is enough to show each of $J_1, \dots J_k$. Axioms hold unconditionally. If the conclusion of a rule holds it is not necesserily the case that the premises held, in that the conclusion could have been derived by another rule.
\end{remark}

\begin{example}
    Consider the following judgement from $-\ \mathsf{nat}$, where $a\ \mathsf{nat}$ is read as ``$a$ is a natural number''. The following rules form an inductive definition of the judgement form $-\ \mathsf{nat}$:

    $$\frac
        {}
        {\texttt{zero}\ \mathsf{nat}}
      \qquad\qquad\qquad
      \frac
        {a\ \mathsf{nat}}
        {\texttt{succ}(a)\ \mathsf{nat}}
    $$

    We can see that an abt $a$ is zero or is of the form $\texttt{succ}(a)$. We see this by induction on the abt, the set of such abts has an operator $\texttt{succ}$. Taking these rules to be exhaustive, it follows that $\textt{succ}(a)$ is a natural number if and only if $a$ is.
\end{example}

\begin{remark}
    We used the word \emph{exhaustive} without really defining it. By this we mean necessary and sufficient. Which we will define now.
\end{remark}

\begin{defin}
    A collection of rules is considered to define the \emph{strongest} judgement form that \emph{closed under} (or \emph{respects}) those rules. To be closed under the rules means that the rules are \emph{sufficient} to show the validity of a judgement: $J$ holds if there is a way to obtain it using the given rules. To be the \emph{strongest} judgement form closed under the rules means that the rules are also \emph{necessary}: $J$ holds \emph{only if} there is a way to obtain it by applying the rules.
\end{defin}

Let's add some more rules to our example, to get a richer structure.

\begin{example}
    The judgement form $a = b$ expresses the equality of two abts $a$ and $b$. We define it inductively on our abts as we did for $\mathsf{nat}$.
    
    $$\frac
        {}
        {\texttt{zero} = \texttt{zero}}
      \qquad\qquad\qquad
    \frac
        {a = b}
        {\texttt{succ}(a) = \texttt{succ}(b)}
    $$
    Our first rule is an axiom declaring that \texttt{zero} is equal to itself, and our second rule shows that abts of the form $\texttt{succ}$ are equal only if their arguments are. Observe that these are exhaustive rules in that they are necessary and sufficient for the formation of $=$.
\end{example}

\subsection{Derivations}

To show that an inductively defined judgement holds, we need to exhibit a \emph{derivation} of it.

\begin{defin}
    A \emph{derivation} of a judgement is a finite composition of rules, starting with axioms and ending with the judgement. It is a tree in which each node is a rule and whose children are derivations of its premises. We sometimes say that a derivation of $J$ is evidence for the validity of an inductively defined judgement $J$.

    Suppose we have a judgement $J$ and
    $$\frac
        {J_1\quad \cdots\quad J_k}
        {J}
    $$
    is an inference rule. Suppose $\triangledown_1, \dots, \triangledown_k$ are derivations of its premises, then
    $$\frac
        {\triangledown_1\quad \cdots\quad \triangledown_k}
        {J}
    $$
    is a derivation of its conclusion. Notice that if $k=0$ then the node has no children.
\end{defin}

Writing derivations as trees can be very enlightening to how the rules compose. Going back to our example with $\mathsf{nat}$ we can give an example of a derivation.

\begin{example}
    Here is a derivation of the judgement $\texttt{succ}(\texttt{succ}(\texttt{succ}(\texttt{zero})))\ \mathsf{nat}$:
    
    \begin{prooftree}
        \AxiomC{}
        \UnaryInfC{ $\texttt{zero}\ \mathsf{nat}$ }
        \UnaryInfC{ $\texttt{succ}(\texttt{zero})\ \mathsf{nat}$ }
        \UnaryInfC{ $\texttt{succ}(\texttt{succ}(\texttt{zero}))\ \mathsf{nat}$ }
        \UnaryInfC{ $\texttt{succ}(\texttt{succ}(\texttt{succ}(\texttt{zero})))\ \mathsf{nat}$ }
    \end{prooftree}
\end{example}

\begin{remark}
    To show that a judgement is \emph{derivable} we need only give a derivation for it. There are two main methods for finding derivations:
    \begin{itemize}
        \item \emph{Forward chaining} or \emph{bottom-up construction}
        \item \emph{Backward chaining} or \emph{top-down construction}
    \end{itemize}
    
    Forward chaining starts with the axioms and works forward towards the desired conclusion. Backward chaining starts with the desired conclusion and works backwards towards the axioms.
\end{remark}

It is easy to observe the \emph{algorithmic} nature of these two processes. In fact this is an important point to think about, since it may become relevent in the future.

\begin{lemma}
    Given a derivable judgement $J$, there is an algorithm giving a derivation for $J$ by forward chaining.
\end{lemma}

\begin{proof}
    This is not a difficult algorithm to describe. We start with a set of rules $\mathcal{R} := \varnothing $ which we initially set to be empty. Now we consider all the rules that have premises in $\mathcal{R}$, initially this will be all the axioms. We add these rules to $\mathcal{R}$ and repeat this process until $J$ appears as a conclusion of one of the rules in $\mathcal{R}$. It is not difficult to see that this will necesserily give all derivations of all derivable judgements and since $J$ is derivable, it will eventually give a derivation for $J$.
\end{proof}

\begin{remark}
    Notice how we had to specify that our judgement is derivable. Since if were not, then our process would not terminate, hence would not be an algorithm. It is also worth noting that this algorithm is very inefficient since the size of $\mathcal{R}$ will grow rapidly, especially when we have more rules available. This is sort of a brute force approach. What we will need is more clever picking of the rules we wish to add. Mathematically this is an algorithm, but not in any practical sense.
\end{remark}

Forward chaining does not take into account any of the information given by the judgement $J$. The algorithm is in a sense blind. 

\begin{lemma}
    Given a derivable judgement $J$, we can give a derivation for $J$ by backward chaining.
\end{lemma}

\begin{proof}
    Backward chaining maintains a queue of goals, judgements whose derivations are to be sought. Initially this consists of the sole judgement we want to derive. At each step, we pick a goal, then we pick a rule whose conclusion is our picked goal and add the premises of the rule to our list of goals. Since $J$ is derivable there must be a derivation that can be chosen.
\end{proof}

\begin{remark}
    We could as before consider all possible goals generated by all possible rules which would technically give us an algorithm like in the case for forward chaining. But it would also be as useless as that algorithm. What backward chaining allows us to do however is better pick to rules at each stage. This is the structure that type checkers will take later on and even proof assitants, programs that assist a user in proving a statement formally. Due to each stage giving us information about the kind of rule we ought to pick, backward chaining is more suitable for algorithmically proving something. In face if we set up our rules in such a way that for each goal there is only one such rule to pick, we have an algorithm!
\end{remark}

\subsection{Rule induction}

[[Write about proving properties about a derivable judgement it suffices to show the property is closed under the defining judgement form]]

[[ We should also go back and consider the discussion on forward and backward chaining because I may have made some things up there. We will need to find some references about this]]

After we have rule induction, we can prove a few lemmas about our natural numbers example.


\begin{lemma}
    If $\texttt{succ}(a)\ \mathsf{nat}$, then $a\ \mathsf{nat}$.
\end{lemma}

\begin{proof}
    By induction on $\texttt{succ}(a)$, when $\texttt{succ}(a)$ is $\texttt{zero}$ this is vacously true. Otherwise when $\texttt{succ}(a)$ is $\text{succ}(b)$, what we want to prove is $\texttt{succ}(b)\ \mathsf{nat} \implies b\ \mathsf{nat}$ but this is exactly our induction hypothesis.
\end{proof}


\begin{lemma}[Reflexivity of $=$]
    If $a\ \mathsf{nat}$, then $a = a$.
\end{lemma}

\begin{proof}
    By induction on $a$ we have two cases which are exactly the two rules about $=$ to begin with.
\end{proof}


\begin{lemma}[Injectivity of \texttt{succ}]\label{inj_succ}
    If $\texttt{succ}(a_1) = \texttt{succ}(a_2)$, then $a_1 = a_2$.
\end{lemma}

\begin{proof}
    We perform induction on $\texttt{succ}(a_1)$ and $\texttt{succ}(a_2)$. Note that if any of the two are of the form $\texttt{zero}$ then the statement is true vacously. When $\texttt{succ}(a_1)$ is of the form $\texttt{succ}(b_1)$ and $\texttt{succ}(a_2)$ is of the form $\texttt{succ}(b_2)$ our statement that we want to prove is exactly what we get from the induction hypothesis.
\end{proof}


\begin{lemma}[Symmetry of $=$]
    If $a = b$, then $b = a$.
\end{lemma}

\begin{proof}
    Begin with induction on $a$ and $b$:
    \begin{itemize}
        \item Suppose $a$ is of the form $\texttt{zero}$ and $b$ is of the form $\texttt{zero}$ then we have $\texttt{zero} = \texttt{zero}$ as desired.
        \item Suppose $a$ is of the form $\texttt{zero}$ and $b$ is of the form $\texttt{succ}(b')$ then our statement is vacously true. The same happens for when $b$ is $\texttt{zero}$ and $a$ is of the form $\texttt{succ}(a')$.
        \item Finally when $a$ is of the form $\texttt{succ}(a')$ and $b$ is of the form $\texttt{succ}(b')$ we have $\texttt{succ}(a')= \texttt{succ}(b')$. By \ref{inj_succ} we have $a'=b'$ and by our induction hypothesis we have $b' = a'$ as desired.
    \end{itemize}
\end{proof}


\begin{lemma}[Transitivity of $=$]
    If $a = b$ and $b = c$ then $a = c$.
\end{lemma}

\begin{proof}
    By induction on $a$, $b$ and $c$ we see that we have eight cases. Clearly six of these are vacously true, so we will prove the other two:
    \begin{itemize}
        \item When $a$, $b$ and $c$ are of the form $\texttt{zero}$ our statement holds trivially.
        \item Whne $a$, $b$ and $c$ are of the form $\texttt{succ}(a')$, $\texttt{succ}(b')$ and $\texttt{succ}(c')$ respectively, we can apply \ref{inj_succ} on $\texttt{succ}(a') =\texttt{succ}(b')$ and $\texttt{succ}(b') = \texttt{succ}(c')$ to get $a' = b'$ and $b' = c'$. Then applying our induction hypothesis we have $a' = c'$, finally applying the second rule for $=$ we have $\texttt{succ}(a') =\texttt{succ}(c')$.
    \end{itemize}
\end{proof}

Finally we can say our four rules correspond to Peano arithmetic!

[[Now talk about how classically peano arithmetic requires many more axioms, we only have four rules and the notion of induction!]]
[[Talk about what we have proven about peano arithematic is actually a meta statement, a statement in the metalanguage, later we will have richer logics where we can prove this internally]].

[[References include Aczel 1977 who provides a thorough account of inductive definitions and judgement based logic is inspired by Martin-Lof's logic of judgements 1983, 1987]]

\subsection{Hypothetical judgements}

\subsubsection{Derivability}

\subsubsection{Admissibility}

\subsection{Hypothetical inductive definitions}



